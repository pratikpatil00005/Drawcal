# Llama Configuration
LLAMA_MODEL_PATH=/path/to/your/llama/model.gguf
LLAMA_CPP_PATH=/path/to/llama/cpp/executable

# Local Llama Configuration
LOCAL_LLAMA_PATH=/path/to/llama/executable
LOCAL_LLAMA_MODEL_PATH=/path/to/llama/model.gguf

# OpenAI Configuration (for Langchain)
OPENAI_API_KEY=your_openai_api_key

# Service Selection
DEFAULT_AI_SERVICE=llama

GROQ_API_KEY=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
AI_SERVICE=groq
OLLAMA_HOST=http://localhost:11434
USE_MOCK_GROQ=true
